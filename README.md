# ğŸ§ ğŸ–ï¸ MotionSpeak: Real-Time Hindi Sign Language Recognizer

## ğŸ“Œ Overview

**MotionSpeak** bridges the communication gap for the hearing and speech-impaired by recognizing Hindi Sign Language in real-time using computer vision and deep learning. The system converts hand gestures into readable text, allowing seamless interaction with non-sign language users.

## ğŸ¯ Goal

To build an affordable and accessible system that enables real-time Hindi Sign Language recognition using just a webcam â€” no gloves or external sensors needed.

## ğŸš€ Features

- ğŸ–ï¸ Recognizes dynamic hand gestures from live webcam feed  
- ğŸ”¤ Outputs corresponding Hindi letters/words in real-time  
- ğŸ¤– Powered by deep learning (CNN/LSTM) for robust gesture classification  
- ğŸŒ Simple and intuitive GUI for ease of use  
- ğŸ“ˆ High accuracy with custom-trained dataset  

## ğŸ› ï¸ Tech Stack

Language: Python  
Libraries: OpenCV, NumPy, TensorFlow/Keras, Tkinter  
Models: CNN (for spatial features), LSTM (for motion/temporal sequence)  
Hardware: Standard webcam

## ğŸ§  Model Architecture

- Input: Live video frames  
- Preprocessing: Background subtraction, contour extraction  
- Feature Extraction: CNN  
- Temporal Modeling: LSTM  
- Output: Hindi character prediction  

## ğŸ§ª How to Run

1. Clone the repository:
   git clone https://github.com/harsharora-8/MotionSpeak.git
   cd MotionSpeak

2. Install dependencies:
   pip install -r requirements.txt

3. Run the app:
   python app.py

4. Show hand gestures in front of your webcam and get real-time predictions!

## ğŸš§ Future Improvements

- Add Text-to-Speech (TTS) output  
- Translate full sign language phrases  
- Create a mobile app (TensorFlow Lite)  
- Add multi-language support (English/ASL)

## ğŸ¤ Contribution

1. Fork the repo  
2. Create a feature branch  
3. Commit and push your changes  
4. Raise a pull request  
5. Get reviewed and merged ğŸ‰

## ğŸ™Œ Acknowledgements

- Contributors and testers  
- OpenCV and TensorFlow communities  
- Sign language trainers and educators  

---

Made with ğŸ’› to empower inclusivity through technology.
